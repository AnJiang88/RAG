{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "595082a1-526b-4c96-afe2-9fec2ca2924f",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation (RAG) with open-source Hugging Face LLMs using LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e6fb0d-db38-46df-9b2b-a7b5058c4dac",
   "metadata": {},
   "source": [
    "![RAG pic](images/RAG.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcf48ed-bb4f-481e-8051-7c4b2dbceee8",
   "metadata": {},
   "source": [
    "## Introduction: \n",
    "\n",
    "**Retrieval-Augmented Generation (RAG)** is an approach in natural language processing (NLP) that enhances the capabilities of generative models by integrating external knowledge retrieval into the generation process. This technique aims to improve the quality, relevance, and factual accuracy of the generated text by allowing the model to dynamically access and incorporate information from a large corpus of documents or databases during the generation task. The process involves two key components: a retrieval system and a generative model.\n",
    "\n",
    "**Working Mechanism**\n",
    "\n",
    "The working mechanism of RAG typically involves the following steps:\n",
    "\n",
    "- Query Formation: The system formulates a query based on the initial input or prompt. This query is designed to retrieve information that is likely to be relevant to generating the desired output.\n",
    "\n",
    "- Information Retrieval: The formulated query is used to fetch relevant information from an external database or knowledge base. The retrieval system may return one or more documents, passages, or data entries that match the query.\n",
    "\n",
    "- Content Integration: The retrieved information, along with the original input, is provided to the generative model. The model then integrates this information to produce a coherent and contextually enriched output.\n",
    "\n",
    "- Generation: The generative model synthesizes the final text, taking into account both the input and the retrieved external information. This step ensures that the output is not only relevant and informative but also maintains a natural and fluent language style.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5260f0f7-e8a5-4051-9aed-42c7729ac92d",
   "metadata": {},
   "source": [
    "## Library installation\n",
    "- Create a virtual environment and install the necessary python libraries\n",
    "- `pip install transformers sentence-tranformers langchain torch faiss-cpu numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cf1fe1-d539-4099-8967-5ce05c2be2a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Library configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "280bbd1d-5b03-403c-989a-fe44ec3efc27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330b1dd5-d9b4-466c-ad18-8adb9e785470",
   "metadata": {},
   "source": [
    "## Document preparation\n",
    "**We are going to download 4 publications from United States Census Bureau on the following topics:**\n",
    "- Occupation, Earnings, and Job Characteristics: July 2022\n",
    "- Household Income in States andMetropolitan Areas: 2022\n",
    "- Poverty in States and Metropolitan Areas: 2022\n",
    "- Health Insurance Coverage Status and Type by Geography: 2021 and 2022\n",
    "\n",
    "We prepare this documents for the LLM to use as a knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da88ba1c-1f1f-400f-bc28-b9bd60a1e6d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download documents from U.S. Census Bureau to local directory.\n",
    "os.makedirs(\"us_census\", exist_ok=True)\n",
    "files = [\n",
    "    \"https://www.census.gov/content/dam/Census/library/publications/2022/demo/p70-178.pdf\",\n",
    "    \"https://www.census.gov/content/dam/Census/library/publications/2023/acs/acsbr-017.pdf\",\n",
    "    \"https://www.census.gov/content/dam/Census/library/publications/2023/acs/acsbr-016.pdf\",\n",
    "    \"https://www.census.gov/content/dam/Census/library/publications/2023/acs/acsbr-015.pdf\",\n",
    "]\n",
    "for url in files:\n",
    "    file_path = os.path.join(\"us_census\", url.rpartition(\"/\")[2])\n",
    "    urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fca755-2b10-4cef-a084-fc1596697f7f",
   "metadata": {},
   "source": [
    "**Split documents to smaller chunks** \n",
    "\n",
    "Documents should be: \n",
    "- large enough to contain enough information to answer a question, and \n",
    "- small enough to fit into the LLM prompt: Mistral-7B-v0.1 input tokens limited to 4096 tokens\n",
    "- small enough to fit into the embeddings model: BAAI/bge-small-en-v1.5: input tokens limited to 512 tokens (roughly 2000 characters. Note: 1 token ~ 4 characters).\n",
    "\n",
    "For this project, we are going to split documents to chunks of roughly 500 characters with an overlap of 50 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b58c08-9077-4f68-9dd6-0333b5bb10a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load pdf files in the local directory\n",
    "loader = PyPDFDirectoryLoader(\"./us_census/\")\n",
    "\n",
    "docs_before_split = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 700,\n",
    "    chunk_overlap  = 50,\n",
    ")\n",
    "docs_after_split = text_splitter.split_documents(docs_before_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11a38354-0612-42ba-bde3-0cfa4514f540",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Health Insurance Coverage Status and Type \\nby Geography: 2021 and 2022\\nAmerican Community Survey Briefs\\nACSBR-015Issued September 2023Douglas Conway and Breauna Branch\\nINTRODUCTION\\nDemographic shifts as well as economic and govern-\\nment policy changes can affect people’s access to health coverage. For example, between 2021 and 2022, the labor market continued to improve, which may have affected private coverage in the United States \\nduring that time.\\n1 Public policy changes included \\nthe renewal of the Public Health Emergency, which \\nallowed Medicaid enrollees to remain covered under the Continuous Enrollment Provision.\\n2 The American', metadata={'source': 'us_census/acsbr-015.pdf', 'page': 0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_after_split[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79aeb73e-5c39-46b6-b144-395ade93c366",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before split, there were 63 documents loaded, with average characters equal to 3830.\n",
      "After split, there were 400 documents (chunks), with average characters equal to 618 (average chunk length).\n"
     ]
    }
   ],
   "source": [
    "avg_doc_length = lambda docs: sum([len(doc.page_content) for doc in docs])//len(docs)\n",
    "avg_char_before_split = avg_doc_length(docs_before_split)\n",
    "avg_char_after_split = avg_doc_length(docs_after_split)\n",
    "\n",
    "print(f'Before split, there were {len(docs_before_split)} documents loaded, with average characters equal to {avg_char_before_split}.')\n",
    "print(f'After split, there were {len(docs_after_split)} documents (chunks), with average characters equal to {avg_char_after_split} (average chunk length).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b957ff3-df1a-4e75-9192-1b9c8c85927b",
   "metadata": {},
   "source": [
    "## Text Embeddings with Hugging Face Embedding Models\n",
    "At the time of writing, there are 213 text embeddings models for English on the [Massive Text Embedding Benchmark (MTEB) leaderboard](https://huggingface.co/spaces/mteb/leaderboard). For our project, we are using LangChain's HuggingFaceBgeEmbeddings (BGE models on the Hugging Face), which according to LangChain are \"the best open-source embedding models\". Currently, **BAAI/bge-small-en-v1.5** model is the 26th on MTEB leaderboard with max tokens: 512 tokens, embedding dimensions: 384 and model size: 0.13GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cbff637-d938-445d-b769-a2122ded10f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anjiang/anaconda3/envs/chatbot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "huggingface_embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\",  # alternatively use \"sentence-transformers/all-MiniLM-l6-v2\" for a light and faster experience.\n",
    "    model_kwargs={'device':'cpu'}, \n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98862ede-96af-4d76-ba54-758eecc11932",
   "metadata": {},
   "source": [
    "Now we can see how a sample embedding would look like for one of those chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b35b55a-3e96-4352-bf5a-5156bb1b5fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample embedding of a document chunk:  [-5.05341105e-02 -1.07632270e-02 -3.22085544e-02  4.64025103e-02\n",
      "  5.17265312e-02  7.26014972e-02 -1.94752328e-02  3.01966239e-02\n",
      " -1.02138393e-01 -1.42446337e-02  6.02175333e-02  6.26361370e-02\n",
      " -2.24274900e-02 -3.16375606e-02 -1.75427161e-02  2.35421602e-02\n",
      " -1.67436562e-02 -2.35973559e-02 -4.86446880e-02  3.57785411e-02\n",
      " -3.60898674e-02  4.26089205e-02 -3.19934972e-02 -5.33743724e-02\n",
      "  2.33906470e-02 -6.23918232e-03 -2.61042379e-02  2.67632008e-02\n",
      " -5.50710484e-02 -1.58236027e-01  1.29768457e-02  2.72521675e-02\n",
      " -5.12634665e-02 -1.78339947e-02  1.00316526e-02 -2.32963008e-03\n",
      " -1.63027493e-03  5.71662150e-02  5.18323965e-02  4.13078591e-02\n",
      " -1.27497157e-02  2.22271308e-02 -2.50611641e-03 -1.75849423e-02\n",
      " -3.96118276e-02  5.91322733e-03 -3.97015028e-02  3.12925153e-03\n",
      "  6.95991376e-03 -4.72989045e-02  4.16573472e-02 -3.69539633e-02\n",
      "  5.37372120e-02  7.53688887e-02  5.36738336e-02 -2.20241938e-02\n",
      "  1.54242031e-02 -1.95292812e-02 -2.51309164e-02  1.57804377e-02\n",
      "  5.04961833e-02 -3.50804743e-03 -2.54900038e-01  8.76260474e-02\n",
      " -1.81502420e-02  4.91284840e-02  1.29146478e-03 -1.97441578e-02\n",
      " -7.29819573e-03 -2.21753940e-02 -6.44287392e-02  4.78182323e-02\n",
      " -5.59540763e-02  1.13018248e-02  4.97898720e-02  3.46819833e-02\n",
      " -2.39175428e-02  1.10386955e-02  2.18980741e-02  1.14973374e-02\n",
      "  3.52493562e-02  4.01748605e-02  3.05161346e-02 -7.08028898e-02\n",
      "  2.81499419e-02 -6.68298677e-02  3.17910314e-02 -3.90256979e-02\n",
      "  1.95806287e-02 -1.00507662e-02 -3.69732752e-02 -7.77440937e-03\n",
      "  1.21968170e-03  5.00512272e-02  2.44037546e-02  3.37037630e-02\n",
      "  1.18802534e-02 -3.72652919e-03 -1.68938674e-02  3.28855842e-01\n",
      " -4.10320722e-02  1.62625778e-02 -2.26146355e-03  2.43743677e-02\n",
      "  7.14171911e-03 -4.25294563e-02 -5.79550071e-03 -6.18778355e-03\n",
      "  3.86953577e-02  1.14670759e-02  8.61893594e-03 -3.70299555e-02\n",
      "  3.26743200e-02  4.74777147e-02 -6.82655722e-02 -3.42685692e-02\n",
      "  4.43274155e-02  2.72197481e-02  1.03154413e-01 -2.45668422e-02\n",
      "  1.17423700e-03  3.03245522e-02  7.65785063e-03 -3.76848876e-02\n",
      "  2.33593937e-02  6.60005808e-02  5.73109463e-02  1.30651623e-01\n",
      "  1.17552029e-02 -4.70488481e-02  8.98687243e-02 -6.69877138e-03\n",
      "  1.49724458e-03  6.43363176e-03  1.01001207e-02  1.45982206e-02\n",
      " -4.22945358e-02  4.15433459e-02  1.36828356e-04  4.97301891e-02\n",
      "  7.03792600e-03 -1.40515426e-02  3.35905212e-03 -1.37325138e-01\n",
      " -3.57701927e-02  1.68024957e-01 -2.25053336e-02  4.25091423e-02\n",
      "  2.85301674e-02  1.76689273e-03 -3.12322862e-02  5.59565239e-02\n",
      " -2.59793568e-02  3.48409861e-02 -2.89765559e-02  2.00114325e-02\n",
      "  2.39206441e-02  5.82966814e-03 -1.98628679e-02 -5.42878620e-02\n",
      "  5.20308763e-02 -2.88052578e-02 -7.05234781e-02  2.73084585e-02\n",
      "  4.42872308e-02 -1.94671787e-02  1.72011927e-02 -4.03976589e-02\n",
      "  5.03398255e-02 -3.26212752e-03  2.97538806e-02  5.38742952e-02\n",
      "  1.24174021e-02 -4.29789349e-02  9.48141590e-02  1.59434434e-02\n",
      " -6.30812952e-03 -9.43207089e-03  1.99717091e-04 -5.13591841e-02\n",
      "  3.08319274e-02 -2.98810564e-02 -5.72830513e-02 -3.75885069e-02\n",
      " -2.83675753e-02 -5.13436534e-02 -3.89444232e-02  5.21872491e-02\n",
      "  6.26989231e-02 -8.91624764e-03 -1.73703041e-02  1.35738980e-02\n",
      " -5.22686131e-02  4.70073931e-02 -9.91425477e-03 -1.05568795e-02\n",
      " -5.96503876e-02 -3.29546742e-02  4.60434370e-02 -4.31321226e-02\n",
      " -4.68126796e-02  2.69842613e-02  3.15763243e-02 -1.24133872e-02\n",
      " -3.39300348e-03  5.66547597e-03  4.99334671e-02 -6.92117587e-02\n",
      "  5.54650016e-02 -9.16964840e-03  4.47344780e-03  3.67193855e-02\n",
      "  5.40467650e-02  8.64493009e-03  3.35856974e-02  1.71162952e-02\n",
      "  1.27363298e-02 -2.12715473e-02  6.49947813e-03  4.51897047e-02\n",
      "  3.69630456e-02  8.09528679e-02  6.18651211e-02 -2.83895791e-01\n",
      " -3.67626883e-02  2.02904250e-02  1.32466909e-02 -6.17055409e-02\n",
      " -4.92665172e-02 -4.30191122e-02  5.56368455e-02  6.67442614e-03\n",
      "  8.21071863e-02  4.47038785e-02  1.32825794e-02 -4.03079614e-02\n",
      "  6.26235679e-02  9.11784824e-03 -6.92342371e-02  3.84197533e-02\n",
      " -2.88692731e-02 -3.01323123e-02 -6.83141360e-03  1.56344622e-02\n",
      "  4.28110547e-03 -8.11247379e-02 -3.39685082e-02  7.31781274e-02\n",
      " -2.42656786e-02  6.82434738e-02 -6.35522902e-02 -7.20293373e-02\n",
      " -1.63071193e-02 -4.42551672e-02  4.13179658e-02 -1.23273814e-02\n",
      " -1.19963095e-01  5.39543442e-02  2.15460341e-02 -9.03444439e-02\n",
      "  2.49267230e-03 -6.97972998e-02 -3.16286273e-02 -1.07019488e-02\n",
      "  5.04211932e-02 -7.36468136e-02  3.09733450e-02 -1.54069066e-02\n",
      " -5.10981604e-02  4.41155247e-02  6.82078376e-02 -6.80729821e-02\n",
      "  1.15152067e-02 -2.53725052e-02 -2.38791779e-02 -1.82392390e-03\n",
      " -1.32775749e-03  2.44128928e-02 -8.46328959e-02 -3.57791558e-02\n",
      "  3.39091271e-02 -2.59201564e-02  6.86673122e-03  7.98944291e-03\n",
      "  1.30604552e-02  4.50623445e-02 -2.22414415e-02 -1.29150013e-02\n",
      " -6.49624765e-02  2.21825112e-03 -3.31460722e-02 -8.35667327e-02\n",
      "  2.04880405e-02  1.08556589e-02  5.63925244e-02 -2.51398347e-02\n",
      " -3.40461396e-02  1.61646400e-02 -1.03724664e-02  5.21015078e-02\n",
      "  1.48746604e-02 -2.30712034e-02 -4.64327484e-02  4.76166643e-02\n",
      " -5.17363735e-02  4.54883976e-03  4.25085984e-02  9.55235213e-03\n",
      "  8.04803392e-04  2.05857046e-02 -5.00059873e-03  7.68260472e-03\n",
      "  2.58051939e-02 -4.14022096e-02 -2.04632990e-03 -1.66158639e-02\n",
      " -4.19208966e-02 -2.53699906e-02 -8.51041079e-03 -2.16603369e-01\n",
      "  4.61369678e-02  4.33526598e-02 -1.45369500e-03 -3.83398117e-04\n",
      " -1.67596564e-02 -4.48084772e-02  1.72318295e-02 -2.00727321e-02\n",
      " -4.30026203e-02  6.09009229e-02  9.34387967e-02  1.20706186e-01\n",
      " -2.41702199e-02 -1.74272377e-02 -5.08245314e-03  7.10281357e-02\n",
      "  9.49263014e-03  6.89389883e-03 -3.91418263e-02  5.13217673e-02\n",
      " -7.03922808e-02  1.45217851e-01 -2.07711905e-02  2.78642625e-02\n",
      " -7.75900260e-02 -2.52508465e-02  4.80836332e-02 -1.09673310e-02\n",
      "  1.31259933e-02  5.82769141e-03  7.87915080e-04  3.34812403e-02\n",
      " -6.02976698e-03  5.12023680e-02 -1.83762833e-02  1.06053855e-02\n",
      "  3.00593805e-02  9.22265369e-03  1.94413438e-02 -3.43024172e-02\n",
      " -1.63307898e-02 -6.49758615e-03  8.18069372e-03  7.30942115e-02\n",
      " -2.57836878e-02 -4.15173247e-02 -4.84157130e-02  4.18341346e-03\n",
      "  7.38446414e-02  8.97014979e-03 -1.83756463e-02 -1.28176706e-02\n",
      "  2.12074444e-02 -5.78511395e-02 -2.00429559e-02 -4.96797264e-02\n",
      "  2.60316711e-02 -2.95332237e-03 -1.83262769e-02  1.66009106e-02\n",
      "  3.39829782e-03 -7.54359066e-02  9.14633041e-04  5.33631966e-02]\n",
      "Size of the embedding:  (384,)\n"
     ]
    }
   ],
   "source": [
    "sample_embedding = np.array(huggingface_embeddings.embed_query(docs_after_split[0].page_content))\n",
    "print(\"Sample embedding of a document chunk: \", sample_embedding)\n",
    "print(\"Size of the embedding: \", sample_embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77031a88-063e-40b7-b543-982e47b037a4",
   "metadata": {},
   "source": [
    "## Retrieval System for vector embeddings\n",
    "Once we have a embedding model, we are ready to vectorize all our documents and store them in a vector store to construct a retrieval system. With specifically designed searching algorithms, a retrieval system can do similarity searching efficiently to retrieve relevant documents.\n",
    "\n",
    "FAISS (Facebook AI Similarity Search) is a library that allows developers to quickly search for embeddings of multimedia documents that are similar to each other. It solves limitations of traditional query search engines that are optimized for hash-based searches, and provides more scalable similarity search functions (nearest-neighbor search implementations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efb25e38-750d-490d-be4a-c15e6d789167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(docs_after_split, huggingface_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "065ce4c9-d269-4c4d-ba44-1856ffaf240f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 documents retrieved which are relevant to the query. Display the first one:\n",
      "\n",
      "in 2022 was $74,755, according \n",
      "Figure 1.\n",
      "Median Household Income in the Past 12 Months in the United States: 2005–2022\n",
      " \n",
      "Note: Estimates for 2020 experimental data not shown. For more information on the 2020 experimental data products, \n",
      "refer to <www.census.gov/programs-surveys/acs/technical-documentation/user-notes/2021-02.html>. Information on conﬁdentiality protection, sampling error, nonsampling error, and deﬁnitions is available at <www.census.gov/acs>.\n",
      "Source: U.S. Census Bureau, 2005–2022 American Community Survey, 1-year estimates.Recession\n",
      "/zero.tab/five.tab/five.tab/six.tab/zero.tab/six.tab/five.tab/seven.tab/zero.tab/seven.tab/five.tab/eight.tab/zero.tab\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"What were the trends in median household income across different states in the United States between 2021 and 2022.\"\"\"  # Sample question, change to other questions you are interested in.\n",
    "relevant_documents = vectorstore.similarity_search(query)\n",
    "print(f'There are {len(relevant_documents)} documents retrieved which are relevant to the query. Display the first one:\\n')\n",
    "print(relevant_documents[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105646d7-b417-41d2-b981-48cae9e20496",
   "metadata": {},
   "source": [
    "### Create a retriever interface using vector store, we'll use it later to construct Q & A chain using LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15c6b860-1146-4256-8aad-5dd5cc245f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use similarity searching algorithm and return 3 most relevant documents.\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2623c760-f5b5-4a07-b303-d33f195b0746",
   "metadata": {},
   "source": [
    "**Now we have our vector store and retrieval system ready. We then need a large language model (LLM) to process information and answer the question.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a8300b-3a58-4026-bf1c-b18ebc7c9c15",
   "metadata": {},
   "source": [
    "## Open-source LLMs from Hugging Face\n",
    "**There two ways to utilize Hugging Face LLMs: online and local.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b62e27-1ce6-41c4-b25e-c154c7cf3cc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hugging Face Hub\n",
    "The Hugging Face Hub is an platform with over 350k models, 75k datasets, and 150k demo apps (Spaces), all open source and publicly available, in an online platform where people can easily collaborate and build ML together. \n",
    "\n",
    "- To use, we should have the huggingface_hub python package installed.\n",
    "- Set an environment variable called HUGGINGFACEHUB_API_TOKEN with your Hugging Face access token in it.\n",
    "- Currently, HuggingFace LangChain integration doesn't support the question-answering task, so we can't select HuggingFace QA models for this project. Instead, we select LLMs from the text-generation task category.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cefbd53a-51c1-4c1a-a05c-b9b0aaa1593a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "# hf = HuggingFaceHub(\n",
    "#     repo_id=\"EleutherAI/gpt-neo-2.7B\",\n",
    "#     model_kwargs={\"temperature\":0.1, \"max_length\":500})\n",
    "\n",
    "#query = \"\"\"What were the trends in median household income across different states in the United States between 2021 and 2022.\"\"\"  # Sample question, change to other questions you are interested in.\n",
    "# hf.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed6e2c-10cc-4c07-a0d9-97386dfcd6f2",
   "metadata": {},
   "source": [
    "Hugging Face Hub will be slow when you run large models. You can get around this by downloading the model and run it on your local machine. This is the way we use LLM in our project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae62f871-4ee2-4296-9a81-53f7eb95f822",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hugging Face Local Pipelines\n",
    "\n",
    "Hugging Face models can be run locally through the HuggingFacePipeline class.\n",
    "\n",
    "- We need to install transformers python package.\n",
    "- The Mistral-7B-v0.1 Large Language Model (LLM) is a pretrained generative text model with 7 billion parameters. Mistral-7B-v0.1 outperforms Llama-2-13B on all benchmarks tested. Read the [paper](https://arxiv.org/abs/2310.06825).\n",
    "- Mistral-7B-v0.1's model size is 3.5GB, while Llama-2–13B has 13 billion parameters and 25GB model size.\n",
    "- In order to use Llama2, you need to request access from Meta. Mistral-7B-v0.1 is publicly available already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35c9a472-a34d-418d-a129-971b987fb023",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:20<00:00, 10.44s/it]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "hf = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"mistralai/Mistral-7B-v0.1\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\"temperature\": 0, \"max_new_tokens\": 300}\n",
    ")\n",
    "\n",
    "llm = hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab280be3-8b48-467e-80bf-1605ff17d616",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anjiang/anaconda3/envs/chatbot/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n## Answer (1)\\n\\nThe data is available here.\\n\\nThe data is in the form of a table, so you can\\'t use `ggplot2` directly. You can use `tidyverse` to convert the table to a data frame and then plot it.\\n\\n```\\nlibrary(tidyverse)\\n\\n# Read the data\\ndata <- read_csv(\"https://www.census.gov/data/tables/time-series/demo/income-poverty/historical-income-households/cps-historical-income-households.csv\")\\n\\n# Convert the table to a data frame\\ndata <- data %>%\\n  as_tibble() %>%\\n  select(Year, State, Median_Household_Income) %>%\\n  mutate(Year = as.numeric(Year))\\n\\n# Plot the data\\nggplot(data, aes(x = Year, y = Median_Household_Income, color = State)) +\\n  geom_line() +\\n  labs(x = \"Year\", y = \"Median Household Income\")\\n```\\n\\nThis will produce the following plot:\\n\\nComment: Thank you so much! I\\'m still learning R and I\\'m not sure how to use the data frame.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e73a4eb-19b1-4b45-a96b-83290d1921a9",
   "metadata": {},
   "source": [
    "**At a glance, our LLM generates some output that might seem plausible but not accurate or factual. That is because it has not been trained on the census data of recent years.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ee0794-fb8c-43e6-bac1-52bd3e8511f1",
   "metadata": {},
   "source": [
    "- OpenAI GPT-3.5 model (for test purpose only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81428990-041a-466d-8a98-29423290a0bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# chat = ChatOpenAI(temperature=0)\n",
    "# chat.invoke(query)\n",
    "# llm = chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67737c0-66f2-447b-b38b-f7dd63794110",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Q & A chain \n",
    "Now we have both the retrieval system for relevant documents and LLM as QA chatbot ready.\n",
    "\n",
    "We will take our initial query, together with the relevant documents retrieved based on the results of our similarity search, to create a prompt to feed into the LLM. The LLM will take the initial query as the question and relevant documents as the context information to generate a result.\n",
    "\n",
    "Luckily, **LangChain** provides an abstraction of the whole pipeline - **RetrievalQA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1814450-da39-4958-bc9a-8f9ce3c99acf",
   "metadata": {},
   "source": [
    "**Let's first construct a proper prompt for our task.**\n",
    "\n",
    "Prompt engineering is another crucial factor in LLM's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c55f5c61-e016-4c26-9038-b063516835ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. Please follow the following rules:\n",
    "1. If you don't know the answer, don't try to make up an answer. Just say \"I can't find the final answer but you may want to check the following links\".\n",
    "2. If you find the answer, write the answer in a concise way with five sentences maximum.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43bc986-93af-49a6-84cc-eda2456f864f",
   "metadata": {},
   "source": [
    "Call LangChain's RetrievalQA with the prompt above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72e1a9bb-7ecb-475a-a7f7-ca974a8a77a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retrievalQA = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c40cd5-6125-4d9b-8c2c-5a6a31497d4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Use RetrievalQA invoke method to execute the chain\n",
    "Note that Input of [invoke method](https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval_qa.base.RetrievalQA.html#langchain.chains.retrieval_qa.base.RetrievalQA.invoke) needs to be a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5f84ff6-7869-44ca-8310-90adec711b6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anjiang/anaconda3/envs/chatbot/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Call the QA chain with our query.\n",
    "result = retrievalQA.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27ba61d2-ea29-4ca4-b94c-cc64232aa972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The median household income in the United States was $74,755 in 2022, according to the U.S. Census Bureau. Median household income was lower than the U.S. median in 30 states and Puerto Rico. It was higher than the U.S. median in 17 states and the District of Columbia. The medians for Arizona, Oregon, and Vermont were not statistically different from the U.S. median.\n",
      "\n",
      "From 2021 to 2022, five states—Alabama, Alaska, Delaware, Florida, and Utah—showed a statistically significant increase in real median household income; 17 states showed a decrease. Real median household income in 2022 was not statistically different from that in 2021 for 28 states, the District of Columbia, and Puerto Rico.\n",
      "\n",
      "The ACS data (which include the PRCS) provide detailed estimates of demographic, social, economic, and housing characteristics for states, congressional districts, metropolitan areas, and counties.\n",
      "\n",
      "The ACS is the largest household survey in the United States, with a sample of about 3.5 million addresses. It covers the housing unit population, which is defined as all people who occupy a housing unit. The ACS collects information on a variety of topics, including age, race, income, comm\n"
     ]
    }
   ],
   "source": [
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86191166-20e2-4b1a-aaa4-f4742542adfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 documents retrieved which are relevant to the query.\n",
      "****************************************************************************************************\n",
      "Relevant Document #1:\n",
      "Source file: us_census/acsbr-017.pdf, Page: 1\n",
      "Content: in 2022 was $74,755, according \n",
      "Figure 1.\n",
      "Median Household Income in the Past 12 Months in the United States: 2005–2022\n",
      " \n",
      "Note: Estimates for 2020 experimental data not shown. For more information on the 2020 experimental data products, \n",
      "refer to <www.census.gov/programs-surveys/acs/technical-documentation/user-notes/2021-02.html>. Information on conﬁdentiality protection, sampling error, nonsampling error, and deﬁnitions is available at <www.census.gov/acs>.\n",
      "Source: U.S. Census Bureau, 2005–2022 American Community Survey, 1-year estimates.Recession\n",
      "/zero.tab/five.tab/five.tab/six.tab/zero.tab/six.tab/five.tab/seven.tab/zero.tab/seven.tab/five.tab/eight.tab/zero.tab\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Relevant Document #2:\n",
      "Source file: us_census/acsbr-017.pdf, Page: 3\n",
      "Content: hold income in 2022 was $24,112 \n",
      "(Table 1 and Figure 2). Median \n",
      "household income was lower than \n",
      "the U.S. median in 30 states and \n",
      "Puerto Rico. It was higher than the \n",
      "U.S. median in 17 states and the \n",
      "District of Columbia. The medians \n",
      "for Arizona, Oregon, and Vermont were not statistically different from \n",
      "the U.S. median.\n",
      "From 2021 to 2022, five states—\n",
      "Alabama, Alaska, Delaware, Florida, \n",
      "and Utah—showed a statistically \n",
      "significant increase in real median \n",
      "household income; 17 states \n",
      "showed a decrease. Real median \n",
      "household income in 2022 was not \n",
      "statistically different from that in \n",
      "2021 for 28 states, the District of \n",
      "Columbia, and Puerto Rico  \n",
      "(Table 1).\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Relevant Document #3:\n",
      "Source file: us_census/acsbr-017.pdf, Page: 0\n",
      "Content: 1 This brief examines a his-\n",
      "torical time series of median household income back to 2005 and analyzes changes in median household income between 2021 and 2022 for the nation, states, the District of Columbia, Puerto Rico, and the 25 most populous metropolitan areas.\n",
      "2, 3 It also includes \n",
      "selected demographic characteristics of the house-holder. Changes in the Gini index between 2021 and 2022 are presented for the nation, states, the District of Columbia, and Puerto Rico.  \n",
      "The ACS data (which include the PRCS) provide \n",
      "detailed estimates of demographic, social, economic, and housing characteristics for states, congressional \n",
      "¹ The U.S. Census Bureau reviewed this data product for unauthor-\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "relevant_docs = result['source_documents']\n",
    "print(f'There are {len(relevant_docs)} documents retrieved which are relevant to the query.')\n",
    "print(\"*\" * 100)\n",
    "for i, doc in enumerate(relevant_docs):\n",
    "    print(f\"Relevant Document #{i+1}:\\nSource file: {doc.metadata['source']}, Page: {doc.metadata['page']}\\nContent: {doc.page_content}\")\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92070ecc-452b-4ef8-a3e7-4b5d13cd548d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- Enhanced Accuracy and Relevance: By leveraging external sources, RAG models can generate content that is more accurate, detailed, and relevant to the given context.\n",
    "- Factuality: It helps in improving the factuality of the generated text, as the information is directly sourced from reliable external databases or knowledge bases.\n",
    "- Versatility: RAG can be applied to a wide range of NLP tasks, including question answering, text summarization, content creation, and more, enhancing their performance by providing access to a broader range of information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
