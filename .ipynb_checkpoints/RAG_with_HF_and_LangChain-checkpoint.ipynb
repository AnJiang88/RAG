{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "595082a1-526b-4c96-afe2-9fec2ca2924f",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation (RAG) with open-source Hugging Face LLMs using LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e6fb0d-db38-46df-9b2b-a7b5058c4dac",
   "metadata": {},
   "source": [
    "![RAG pic](pictures/RAG.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcf48ed-bb4f-481e-8051-7c4b2dbceee8",
   "metadata": {},
   "source": [
    "## Introduction: \n",
    "\n",
    "**Retrieval-Augmented Generation (RAG)** is an approach in natural language processing (NLP) that enhances the capabilities of generative models by integrating external knowledge retrieval into the generation process. This technique aims to improve the quality, relevance, and factual accuracy of the generated text by allowing the model to dynamically access and incorporate information from a large corpus of documents or databases during the generation task. The process involves two key components: a retrieval system and a generative model.\n",
    "\n",
    "**Working Mechanism**\n",
    "\n",
    "The working mechanism of RAG typically involves the following steps:\n",
    "\n",
    "- Query Formation: The system formulates a query based on the initial input or prompt. This query is designed to retrieve information that is likely to be relevant to generating the desired output.\n",
    "\n",
    "- Information Retrieval: The formulated query is used to fetch relevant information from an external database or knowledge base. The retrieval system may return one or more documents, passages, or data entries that match the query.\n",
    "\n",
    "- Content Integration: The retrieved information, along with the original input, is provided to the generative model. The model then integrates this information to produce a coherent and contextually enriched output.\n",
    "\n",
    "- Generation: The generative model synthesizes the final text, taking into account both the input and the retrieved external information. This step ensures that the output is not only relevant and informative but also maintains a natural and fluent language style.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5260f0f7-e8a5-4051-9aed-42c7729ac92d",
   "metadata": {},
   "source": [
    "## Library installation\n",
    "- Create a virtual environment and install the necessary python libraries\n",
    "- `pip install transformers sentence-tranformers langchain torch faiss-cpu numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cf1fe1-d539-4099-8967-5ce05c2be2a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Library configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "280bbd1d-5b03-403c-989a-fe44ec3efc27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anjiang/anaconda3/envs/chatbot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330b1dd5-d9b4-466c-ad18-8adb9e785470",
   "metadata": {},
   "source": [
    "## Document preparation\n",
    "**We are going to download 4 publications from United States Census Bureau on the following topics:**\n",
    "- Occupation, Earnings, and Job Characteristics: July 2022\n",
    "- Household Income in States andMetropolitan Areas: 2022\n",
    "- Poverty in States and Metropolitan Areas: 2022\n",
    "- Health Insurance Coverage Status and Type by Geography: 2021 and 2022\n",
    "\n",
    "We prepare this documents for the LLM to use as a knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da88ba1c-1f1f-400f-bc28-b9bd60a1e6d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download documents from U.S. Census Bureau to local directory.\n",
    "os.makedirs(\"us_census\", exist_ok=True)\n",
    "files = [\n",
    "    \"https://www.census.gov/content/dam/Census/library/publications/2022/demo/p70-178.pdf\",\n",
    "    \"https://www.census.gov/content/dam/Census/library/publications/2023/acs/acsbr-017.pdf\",\n",
    "    \"https://www.census.gov/content/dam/Census/library/publications/2023/acs/acsbr-016.pdf\",\n",
    "    \"https://www.census.gov/content/dam/Census/library/publications/2023/acs/acsbr-015.pdf\",\n",
    "]\n",
    "for url in files:\n",
    "    file_path = os.path.join(\"us_census\", url.rpartition(\"/\")[2])\n",
    "    urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fca755-2b10-4cef-a084-fc1596697f7f",
   "metadata": {},
   "source": [
    "**Split documents to smaller chunks** \n",
    "\n",
    "Documents should be: \n",
    "- large enough to contain enough information to answer a question, and \n",
    "- small enough to fit into the LLM prompt: Mistral-7B-v0.1 input tokens limited to 4096 tokens\n",
    "- small enough to fit into the embeddings model: all-mpnet-base-v2: input tokens limited to 384 tokens (roughly 1500 characters. Note: 1 token ~ 4 characters).\n",
    "\n",
    "For this project, we are going to split documents to chunks of roughly 500 characters with an overlap of 50 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b58c08-9077-4f68-9dd6-0333b5bb10a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load pdf files in the local directory\n",
    "loader = PyPDFDirectoryLoader(\"./us_census/\")\n",
    "\n",
    "docs_before_split = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap  = 50,\n",
    ")\n",
    "docs_after_split = text_splitter.split_documents(docs_before_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11a38354-0612-42ba-bde3-0cfa4514f540",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Health Insurance Coverage Status and Type \\nby Geography: 2021 and 2022\\nAmerican Community Survey Briefs\\nACSBR-015Issued September 2023Douglas Conway and Breauna Branch\\nINTRODUCTION\\nDemographic shifts as well as economic and govern-\\nment policy changes can affect people’s access to health coverage. For example, between 2021 and 2022, the labor market continued to improve, which may have affected private coverage in the United States \\nduring that time.\\n1 Public policy changes included', metadata={'source': 'us_census/acsbr-015.pdf', 'page': 0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_after_split[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79aeb73e-5c39-46b6-b144-395ade93c366",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before split, there were 63 documents loaded, with average characters equal to 3830.\n",
      "After split, there were 576 documents (chunks), with average characters equal to 435 (average chunk length).\n"
     ]
    }
   ],
   "source": [
    "avg_doc_length = lambda docs: sum([len(doc.page_content) for doc in docs])//len(docs)\n",
    "avg_char_before_split = avg_doc_length(docs_before_split)\n",
    "avg_char_after_split = avg_doc_length(docs_after_split)\n",
    "\n",
    "print(f'Before split, there were {len(docs_before_split)} documents loaded, with average characters equal to {avg_char_before_split}.')\n",
    "print(f'After split, there were {len(docs_after_split)} documents (chunks), with average characters equal to {avg_char_after_split} (average chunk length).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b957ff3-df1a-4e75-9192-1b9c8c85927b",
   "metadata": {},
   "source": [
    "## Text Embeddings with Hugging Face Embedding Models\n",
    "At the time of writing, there are 213 text embeddings models for English on the [Massive Text Embedding Benchmark (MTEB) leaderboard](https://huggingface.co/spaces/mteb/leaderboard). For our project, we are using LangChain's HuggingFaceEmbeddings, which only supports **sentence-transformers** embedding models. Currently, the best sentence-transformers embedding model on MTEB is **all-mpnet-base-v2** (max sequence length: 384 tokens, dimensions: 768, size: 420MB). Another sentence-transformers embedding model **all-MiniLM-L6-v2** (max sequence length: 256 tokens, dimensions: 384, size: 80MB) provides close quality but 5 times faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cbff637-d938-445d-b769-a2122ded10f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",  # alternatively use \"sentence-transformers/all-MiniLM-l6-v2\" for a light and faster experience.\n",
    "    model_kwargs={'device':'cpu'}, \n",
    "    encode_kwargs={'normalize_embeddings': False}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98862ede-96af-4d76-ba54-758eecc11932",
   "metadata": {},
   "source": [
    "Now we can see how a sample embedding would look like for one of those chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b35b55a-3e96-4352-bf5a-5156bb1b5fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample embedding of a document chunk:  [-4.33103070e-02  9.73282605e-02 -1.74221173e-02 -1.16056398e-01\n",
      " -1.40246563e-03  2.92262491e-02  4.38641682e-02  4.99014333e-02\n",
      "  8.32912177e-02 -4.58104117e-03  7.65514746e-02  2.53201351e-02\n",
      "  1.26149943e-02  5.29901013e-02  3.35386060e-02 -4.15676124e-02\n",
      " -1.62367355e-02  5.84275201e-02 -4.08476032e-03  5.90218976e-03\n",
      " -7.34952539e-02  1.56117259e-02 -4.89762537e-02  3.38563621e-02\n",
      "  3.42362896e-02  9.21768323e-03  2.33672373e-02 -1.53755620e-02\n",
      " -1.24781756e-02 -4.80748639e-02  6.90151379e-02 -2.54305564e-02\n",
      " -2.47002710e-02 -8.32483321e-02  1.91394065e-06 -4.36883047e-02\n",
      "  4.59129643e-03  4.91034091e-02  1.85815338e-02 -4.82816249e-02\n",
      " -1.48528116e-02 -7.85710961e-02 -6.41152114e-02  1.56047996e-02\n",
      "  2.89277155e-02 -3.18426788e-02 -9.23720840e-03  9.53771267e-03\n",
      " -6.15626387e-02  1.08385680e-03 -3.05190459e-02  1.53597463e-02\n",
      " -8.13634545e-02 -2.76066065e-02 -1.24553833e-02 -2.58729444e-03\n",
      "  1.27911975e-03 -1.16974479e-02  3.72260176e-02 -8.89495164e-02\n",
      "  4.30233777e-03  1.46707462e-03  9.25836270e-04  3.52421217e-02\n",
      " -9.40447859e-03  6.02866560e-02 -2.91008484e-02  6.89407736e-02\n",
      " -7.08456850e-03  6.45371294e-03  7.20250458e-02  1.11075481e-02\n",
      "  2.38301158e-02 -5.05377725e-03 -2.69959122e-03  8.55886564e-03\n",
      "  1.40857557e-03 -1.95646547e-02  1.97443664e-02  1.07827131e-02\n",
      " -3.65946256e-02  3.85462232e-02  1.66206881e-02 -1.96407307e-02\n",
      " -4.01991829e-02  4.08381559e-02 -2.96575087e-03  9.63131804e-03\n",
      " -2.99662929e-02 -3.00857238e-02  1.67274326e-02 -3.18390280e-02\n",
      "  1.42867386e-03  1.98669382e-03  2.51026787e-02 -9.77873802e-03\n",
      " -3.42083187e-03 -5.85466111e-03  8.03602040e-02  2.37738178e-03\n",
      " -3.29515664e-04  2.01648567e-02 -5.80264144e-02  3.55188623e-02\n",
      "  4.20613252e-02 -3.17634195e-02  8.85486952e-04 -4.20665145e-02\n",
      "  2.27126075e-04  6.26925677e-02 -2.11162190e-03  3.13241705e-02\n",
      "  2.48955097e-02  2.55073011e-02  1.10008996e-02  3.94645929e-02\n",
      " -5.51588722e-02 -3.45969833e-02 -3.39554958e-02 -2.28119120e-02\n",
      " -3.18908431e-02 -1.21463360e-02 -1.64578725e-02 -1.17745092e-02\n",
      " -6.45233840e-02  3.36366631e-02  4.81542200e-03  1.78628080e-02\n",
      " -9.00984742e-03  6.63293991e-03  3.64210941e-02 -2.58113188e-03\n",
      "  4.97433841e-02 -4.02188580e-03 -9.68971569e-03 -2.32394561e-02\n",
      "  4.09047343e-02 -5.07944077e-02 -5.04617952e-03  4.45997454e-02\n",
      " -5.17380470e-03  3.34769599e-02 -3.50104012e-02 -4.69863787e-02\n",
      "  2.03761533e-02 -5.32401353e-02 -3.45838293e-02 -3.98424231e-02\n",
      " -1.02216806e-02 -2.97852196e-02 -4.45342064e-02 -1.01995043e-01\n",
      "  1.34030487e-02 -2.46494599e-02  4.63620126e-02  1.71042606e-02\n",
      "  4.18099575e-02 -3.68464319e-03 -2.52274536e-02 -1.38794770e-02\n",
      " -3.39015760e-02 -2.35319939e-02 -4.92062531e-02  6.93303812e-03\n",
      "  3.92730311e-02  6.74941540e-02  4.74913120e-02 -3.34922858e-02\n",
      "  5.37305884e-02  1.46076195e-02 -4.75806259e-02 -1.42029896e-02\n",
      " -2.02822369e-02  3.77971609e-03  4.18340415e-02  6.59896135e-02\n",
      " -1.74486660e-03 -2.12302040e-02 -2.61026919e-02  2.85567697e-02\n",
      " -4.79654707e-02 -9.42281708e-02 -4.56900522e-03 -1.02522396e-01\n",
      " -2.05369834e-02 -3.31188180e-02  2.47910097e-02 -3.18912640e-02\n",
      " -3.34075280e-02  7.31592765e-04  3.59826200e-02 -4.27814014e-02\n",
      "  3.10360342e-02 -2.37114113e-02  1.39587112e-02  3.40777799e-03\n",
      "  1.79313663e-02  4.81072515e-02 -1.86779946e-02  3.68671715e-02\n",
      " -2.68976167e-02 -6.82453513e-02 -3.01894994e-04  2.02059932e-02\n",
      " -5.65638673e-03 -3.07992077e-03 -3.13402750e-02  5.96794300e-02\n",
      "  1.35790100e-02 -1.09449532e-02 -1.99938677e-02  2.40415167e-02\n",
      " -6.88270293e-03  1.30027620e-05  2.32930351e-02  2.80955266e-02\n",
      "  5.56283109e-02  1.29958130e-02  5.08470200e-02  3.82215492e-02\n",
      " -2.65650377e-02  9.88116837e-04  2.88276765e-02 -2.51635406e-02\n",
      "  1.44784320e-02  7.65955672e-02  5.48650650e-03  3.23057757e-03\n",
      " -2.28218194e-02 -1.66066904e-02  1.34236347e-02  1.48395244e-02\n",
      " -3.47906984e-02 -1.07965581e-02  2.12228373e-02  2.01111101e-02\n",
      "  5.81602417e-02  4.09147702e-02 -7.69130094e-03  3.51124327e-03\n",
      "  2.85506714e-02 -4.62248810e-02  5.87985665e-03 -6.75334362e-04\n",
      "  2.29968019e-02 -1.68205611e-02  6.42025424e-03  8.42942111e-03\n",
      "  2.91818427e-03  5.06599098e-02  2.16300669e-03  3.02122528e-04\n",
      " -2.72952244e-02 -4.55674343e-02 -5.85755669e-02 -1.41403452e-02\n",
      " -2.53017824e-02 -1.54712442e-02 -1.46995559e-02  8.45068544e-02\n",
      " -3.98583822e-02 -4.66689765e-02  1.33353751e-03 -2.91825477e-02\n",
      "  2.84690820e-02  8.02318659e-03  3.77599150e-02  3.47954258e-02\n",
      "  4.30725180e-02 -6.26154244e-03 -4.31476831e-02  4.32004966e-02\n",
      "  9.31314379e-03  7.98372179e-03 -2.52331253e-02  2.22013984e-02\n",
      " -3.26331676e-04  5.30635752e-02  3.16698104e-02  1.09790852e-02\n",
      " -1.38530871e-02  2.01853253e-02  2.30981931e-02 -6.64460054e-03\n",
      " -2.59322580e-02 -1.41675640e-02 -2.17174664e-02 -2.48568263e-02\n",
      "  9.20991972e-03 -5.81456721e-03  3.44806612e-02  4.46570367e-02\n",
      " -6.87360857e-03 -2.05537248e-02 -3.71745750e-02 -2.92630563e-03\n",
      " -4.34450172e-02 -2.25874782e-02 -4.33833934e-02  1.09943154e-03\n",
      "  1.57365706e-02  4.98933904e-02  1.28764734e-02  1.69175919e-02\n",
      " -4.40647639e-03 -1.29918940e-02 -6.96529401e-03 -3.48496772e-02\n",
      "  2.23034192e-02  1.89910345e-02  4.60687540e-02  1.41735410e-03\n",
      "  1.02411769e-02 -3.42250392e-02 -2.13243756e-02 -9.32067633e-03\n",
      " -1.80662293e-02  8.50917622e-02  1.19366646e-02  4.99929041e-02\n",
      "  2.69845910e-02 -2.53234152e-02 -5.25881387e-02  7.21240565e-02\n",
      "  7.92016163e-02 -5.10196611e-02 -5.65683357e-02 -5.48185669e-02\n",
      " -4.54130583e-02 -1.50176056e-03 -3.42151560e-02  3.31603028e-02\n",
      " -6.28244411e-03  4.59241634e-03 -3.67975831e-02 -5.79485856e-02\n",
      " -2.74818055e-02  4.51950841e-02  5.97714027e-03  9.93037503e-03\n",
      " -4.37061861e-02 -6.10647760e-02  1.56297404e-02 -6.09161258e-02\n",
      "  2.59512682e-02  1.36238029e-02  5.32824583e-02 -1.18076894e-02\n",
      " -1.03180399e-02  3.79914045e-02 -3.00424211e-02  1.07365057e-01\n",
      " -1.19251208e-02  2.34186035e-02 -7.43357278e-03 -4.88152690e-02\n",
      "  2.75814272e-02  4.28160876e-02 -7.30433986e-02  1.90261547e-02\n",
      " -4.03003097e-02  8.29458982e-03  3.60334329e-02  6.61176965e-02\n",
      "  1.03557957e-02  3.31874900e-02  3.75782576e-04 -3.02302148e-02\n",
      " -2.34685317e-02  2.65385341e-02  6.13737386e-03 -4.20908350e-03\n",
      "  2.62746420e-02  2.40448248e-02 -2.25497596e-02  2.35210918e-03\n",
      "  3.51315993e-03 -8.80364422e-03 -1.07646817e-02  4.46818732e-02\n",
      "  4.94266115e-02 -2.35687122e-02  7.34165013e-02  9.45113879e-03\n",
      " -4.78375666e-02 -8.25784355e-03  4.29326333e-02 -5.41421818e-03\n",
      " -9.09969117e-03  6.18891791e-03  1.29458336e-02  2.67448314e-02\n",
      " -1.03640119e-02  4.34768572e-02  4.20370623e-02  3.21783833e-02\n",
      " -4.62381430e-02 -4.70982827e-02 -9.22509003e-03 -1.64374476e-04\n",
      "  4.40479582e-03 -1.04037866e-01 -2.56201997e-02  1.64296627e-02\n",
      "  2.80253086e-02 -5.86121604e-02  2.69988179e-02  2.90970579e-02\n",
      " -3.59944813e-02 -2.84009520e-03 -3.68753029e-03  3.17798890e-02\n",
      "  2.11677398e-03  2.16496568e-02  9.31464732e-02 -1.36042526e-02\n",
      "  5.27663855e-03 -5.57827093e-02  2.33408790e-02  1.96366291e-02\n",
      " -3.51056978e-02  3.65273692e-02 -2.42841281e-02 -6.25915378e-02\n",
      " -7.03363307e-03  1.50049618e-02  1.11130677e-01 -2.01994013e-02\n",
      " -3.57539468e-02 -3.19633521e-02  2.43790122e-03  2.06680242e-02\n",
      "  9.53087118e-03  3.73687111e-02 -7.00067505e-02  3.91823649e-02\n",
      "  3.62886265e-02  1.07361013e-02 -4.17025350e-02  3.00907381e-02\n",
      "  3.94457281e-02  1.00830588e-02 -1.98101019e-03 -2.89162416e-02\n",
      " -4.28698696e-02  4.45238091e-02 -1.99196220e-04  3.08347158e-02\n",
      " -1.54927792e-02 -1.83037706e-02 -2.06886306e-02  5.49598336e-02\n",
      " -5.89727499e-02  7.40336627e-03  4.19661924e-02 -3.49267982e-02\n",
      " -1.98244900e-02 -3.00926659e-02  4.05490026e-02  1.17290188e-02\n",
      " -2.50522047e-02  6.12785853e-03  3.09976991e-02  7.43432809e-03\n",
      "  7.26778731e-02  4.38029766e-02 -8.38019140e-03 -3.66215147e-02\n",
      " -1.75164994e-02  1.66483577e-02  2.65412368e-02 -3.66522521e-02\n",
      " -3.68182287e-02  7.02584311e-02 -6.08418435e-02 -2.66102497e-02\n",
      " -2.73108203e-02  7.32749933e-03  3.99527773e-02 -5.88104948e-02\n",
      " -7.50117295e-04 -1.35524869e-02  2.18544193e-02  1.97256706e-03\n",
      " -9.40574054e-03  1.65850241e-02  2.17644274e-02 -1.41169010e-02\n",
      " -7.09025934e-03  4.06019250e-03  1.14473691e-02 -1.05762463e-02\n",
      " -3.06924190e-02 -5.57566714e-03  1.67957656e-02 -3.80503247e-03\n",
      " -5.15182689e-03  7.28017837e-02 -9.05629899e-03 -7.04091089e-03\n",
      " -1.17722806e-02 -3.04708611e-02  2.50572246e-02  3.98963690e-02\n",
      " -4.84525645e-03  8.61684904e-02  1.10347867e-02  7.52981082e-02\n",
      "  7.97657017e-03 -1.13549512e-02 -2.41796579e-02  1.89756621e-02\n",
      "  7.38358730e-03 -2.40594968e-02  1.94360800e-02  3.51840369e-02\n",
      " -4.10187000e-04 -2.10899254e-03  3.53179947e-02  2.48913709e-02\n",
      " -3.53652015e-02  1.87243056e-02  3.02075688e-02 -1.98977347e-03\n",
      " -1.60552431e-02  7.52923079e-03 -3.84797975e-02 -2.15493217e-02\n",
      " -1.26258386e-02  2.67228056e-02  6.19510040e-02 -1.89065821e-02\n",
      " -4.54528257e-03  7.35535100e-02  2.31439956e-02  1.28453888e-03\n",
      "  9.57224332e-03  3.29965502e-02 -5.78784272e-02 -1.89250726e-02\n",
      " -1.35418233e-02 -3.08951773e-02  1.31047806e-02 -5.91696911e-02\n",
      "  2.75632250e-03 -2.03834474e-02 -2.61117928e-02 -3.82435657e-02\n",
      " -3.73723754e-03 -8.36265385e-02  2.23024376e-03  3.73695381e-02\n",
      " -5.04711680e-02 -3.18879355e-03  2.09314134e-02 -5.22115395e-33\n",
      " -3.87252159e-02 -6.12919927e-02  7.79071706e-04 -9.58447754e-02\n",
      " -2.02111565e-02  1.16536627e-02  1.23104928e-02 -3.31238210e-02\n",
      "  2.39643212e-02 -4.61320318e-02 -4.32269229e-03  1.93011258e-02\n",
      "  7.93848652e-03  2.40650121e-02  6.30463958e-02 -1.35755120e-02\n",
      " -2.29289550e-02  1.19441729e-02 -1.39509356e-02  2.74429470e-02\n",
      " -8.82361010e-02 -6.14362862e-03  6.06538402e-03  2.09274655e-03\n",
      "  1.63552780e-02  3.23597416e-02  3.16668041e-02 -7.01278225e-02\n",
      " -2.76253633e-02  2.53743865e-02 -2.28343830e-02  3.64353582e-02\n",
      "  3.74001265e-02 -4.85374406e-02  5.32201119e-02  1.59082282e-02\n",
      " -7.08796259e-04 -7.27521107e-02 -3.50673161e-02 -1.92384459e-02\n",
      " -3.02295275e-02 -7.21798986e-02 -5.51009886e-02  5.31830452e-02\n",
      "  4.27784584e-03 -7.23066032e-02 -1.94253344e-02 -1.22720851e-02\n",
      " -1.96286128e-03  2.11284626e-02  6.74671903e-02  4.14583944e-02\n",
      " -2.06194706e-02  7.82945156e-02 -9.53848138e-02  8.30061212e-02\n",
      " -1.83087680e-02  6.86598644e-02  4.47259024e-02 -1.08711291e-02\n",
      "  1.49251511e-02  3.56139503e-02  4.36728168e-03 -5.02532795e-02\n",
      "  3.04505154e-02 -1.43406298e-02 -1.67410951e-02  2.24870164e-02\n",
      " -6.50560260e-02 -2.91891899e-02  5.73569722e-03 -1.31958006e-02\n",
      " -7.23918155e-02  2.52735354e-02 -3.12643088e-02 -2.99714319e-02\n",
      "  7.08145974e-03  5.27094752e-02 -3.45446332e-03 -2.58487295e-02\n",
      "  1.93207525e-02 -1.12776943e-02 -4.03002091e-02 -1.46351000e-02\n",
      " -5.44222072e-02 -5.90508245e-02  2.43803170e-02 -1.78599812e-03\n",
      " -5.01274876e-03  2.55735833e-02  5.33157103e-02  8.48844871e-02\n",
      " -2.04550773e-02 -1.29321543e-02 -1.48760369e-02 -4.16396558e-02\n",
      "  2.65529584e-02 -4.68853768e-03 -2.28157397e-02  9.59712919e-03\n",
      " -2.49027684e-02  3.70669588e-02 -3.21673900e-02  5.08435778e-02\n",
      " -4.77753114e-03  2.50469279e-02  1.19743834e-03 -3.15042213e-02\n",
      " -7.98152760e-02 -1.02091562e-02  6.72839954e-02 -6.24402659e-03\n",
      " -1.50886979e-02  2.24542376e-02  2.90482640e-02  2.27522440e-02\n",
      "  3.36494185e-02  1.47163263e-02  4.06200474e-04 -6.68373425e-03\n",
      " -1.59597751e-02 -2.84809694e-02 -5.14577813e-02  3.88288521e-03\n",
      " -6.70985579e-02  3.71377356e-02 -7.19812606e-03  1.39386747e-02\n",
      "  2.08768193e-02 -5.44378422e-02  3.19364555e-02 -3.73584665e-02\n",
      "  2.44124095e-07  4.38393280e-02 -1.42256403e-02 -3.21674682e-02\n",
      " -1.65114067e-02  6.45351186e-02 -1.69278644e-02  1.67929381e-02\n",
      " -4.83717620e-02  3.06108147e-02  6.56359866e-02  5.99007532e-02\n",
      " -5.11184856e-02 -2.29752678e-02  7.07818242e-03 -3.37169766e-02\n",
      "  1.06947951e-01 -1.29430499e-02  7.57304532e-03 -6.20216690e-02\n",
      "  2.12154835e-02  3.24438624e-02  3.09762117e-02 -1.94962583e-02\n",
      " -2.37449352e-02  1.03619313e-02  5.93502373e-02  2.08718074e-03\n",
      " -4.52211089e-02 -3.83243337e-02 -4.02032435e-02 -5.54579534e-02\n",
      "  1.51702221e-02 -4.79742745e-03  1.58290546e-02 -3.05483546e-02\n",
      "  3.43649387e-02 -1.87580623e-02  6.78444356e-02 -7.49444822e-03\n",
      "  2.21363246e-03 -6.89354958e-03 -9.14302282e-03 -1.00605087e-02\n",
      " -3.23466212e-02  6.77710250e-02 -2.35486520e-03 -5.15060425e-02\n",
      " -9.03542191e-02 -3.14255208e-02 -7.37720449e-03  3.28904837e-02\n",
      " -2.50265177e-04 -4.65410948e-02 -1.38353761e-02  2.77020298e-02\n",
      "  1.86134037e-02  1.45695424e-02  4.30404358e-02  6.26645470e-03\n",
      "  3.14796790e-02 -1.23271230e-03 -2.37240195e-02  2.12354213e-02\n",
      "  6.09824583e-02  3.58427572e-03 -1.72570925e-02 -1.54531505e-02\n",
      "  2.12386712e-34  1.31791029e-02  1.02629466e-02 -1.79655608e-02\n",
      " -6.53170794e-02  4.66103442e-02 -2.23673284e-02  3.69285345e-02\n",
      "  2.00531855e-02 -7.27272639e-03  1.26427161e-02  7.28393346e-03]\n",
      "Size of the embedding:  (768,)\n"
     ]
    }
   ],
   "source": [
    "sample_embedding = np.array(huggingface_embeddings.embed_query(docs_after_split[0].page_content))\n",
    "print(\"Sample embedding of a document chunk: \", sample_embedding)\n",
    "print(\"Size of the embedding: \", sample_embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77031a88-063e-40b7-b543-982e47b037a4",
   "metadata": {},
   "source": [
    "## Retrieval System for vector embeddings\n",
    "Once we have a embedding model, we are ready to vectorize all our documents and store them in a vector store to construct a retrieval system. With specifically designed searching algorithms, a retrieval system can do similarity searching efficiently to retrieve relevant documents.\n",
    "\n",
    "FAISS (Facebook AI Similarity Search) is a library that allows developers to quickly search for embeddings of multimedia documents that are similar to each other. It solves limitations of traditional query search engines that are optimized for hash-based searches, and provides more scalable similarity search functions (nearest-neighbor search implementations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efb25e38-750d-490d-be4a-c15e6d789167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(docs_after_split, huggingface_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "065ce4c9-d269-4c4d-ba44-1856ffaf240f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 documents retrieved which are relevant to the query. Display the first one:\n",
      "\n",
      "programs-surveys/acs>.\n",
      "HIGHLIGHTS\n",
      "• Median household income in the United States was $74,755 in 2022, a decline of 0.8 percent from last year, after adjusting for inflation.\n",
      "6\n",
      "• Real median household income increased in five states and decreased in 17 states from 2021 to 2022. Twenty-eight states, the District of Columbia, and \n",
      "Puerto Rico showed no statisti-\n",
      "cally significant differences. \n",
      "⁶ All income estimates in this report \n",
      "are inflation-adjusted to 2022 dollars.\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"What were the trends in median household income across different states in the United States between 2021 and 2022.\"\"\"  # Sample question, change to other questions you are interested in.\n",
    "relevant_documents = vectorstore.similarity_search(query)\n",
    "print(f'There are {len(relevant_documents)} documents retrieved which are relevant to the query. Display the first one:\\n')\n",
    "print(relevant_documents[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105646d7-b417-41d2-b981-48cae9e20496",
   "metadata": {},
   "source": [
    "### Create a retriever interface using vector store, we'll use it later to construct Q & A chain using LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15c6b860-1146-4256-8aad-5dd5cc245f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use similarity searching algorithm and return 3 most relevant documents.\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2623c760-f5b5-4a07-b303-d33f195b0746",
   "metadata": {},
   "source": [
    "**Now we have our vector store and retrieval system ready. We then need a large language model (LLM) to process information and answer the question.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a8300b-3a58-4026-bf1c-b18ebc7c9c15",
   "metadata": {},
   "source": [
    "## Open-source LLMs from Hugging Face\n",
    "**There two ways to utilize Hugging Face LLMs: online and local.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b62e27-1ce6-41c4-b25e-c154c7cf3cc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hugging Face Hub\n",
    "The Hugging Face Hub is an platform with over 350k models, 75k datasets, and 150k demo apps (Spaces), all open source and publicly available, in an online platform where people can easily collaborate and build ML together. \n",
    "\n",
    "- To use, we should have the huggingface_hub python package installed.\n",
    "- Set an environment variable called HUGGINGFACEHUB_API_TOKEN with your Hugging Face access token in it.\n",
    "- Currently, HuggingFace LangChain integration doesn't support the question-answering task, so we can't select HuggingFace QA models for this project. Instead, we select LLMs from the text-generation task category.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cefbd53a-51c1-4c1a-a05c-b9b0aaa1593a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "# hf = HuggingFaceHub(\n",
    "#     repo_id=\"EleutherAI/gpt-neo-2.7B\",\n",
    "#     model_kwargs={\"temperature\":0.1, \"max_length\":500})\n",
    "\n",
    "#query = \"\"\"What were the trends in median household income across different states in the United States between 2021 and 2022.\"\"\"  # Sample question, change to other questions you are interested in.\n",
    "# hf.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed6e2c-10cc-4c07-a0d9-97386dfcd6f2",
   "metadata": {},
   "source": [
    "Hugging Face Hub will be slow when you run large models. You can get around this by downloading the model and run it on your local machine. This is the way we use LLM in our project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae62f871-4ee2-4296-9a81-53f7eb95f822",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hugging Face Local Pipelines\n",
    "\n",
    "Hugging Face models can be run locally through the HuggingFacePipeline class.\n",
    "\n",
    "- We need to install transformers python package.\n",
    "- The Mistral-7B-v0.1 Large Language Model (LLM) is a pretrained generative text model with 7 billion parameters. Mistral-7B-v0.1 outperforms Llama-2-13B on all benchmarks tested. Read the [paper](https://arxiv.org/abs/2310.06825).\n",
    "- Mistral-7B-v0.1's model size is 3.5GB, while Llama-2–13B has 13 billion parameters and 25GB model size.\n",
    "- In order to use Llama2, you need to request access from Meta. Mistral-7B-v0.1 is publicly available already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35c9a472-a34d-418d-a129-971b987fb023",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:19<00:00,  9.67s/it]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "hf = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"mistralai/Mistral-7B-v0.1\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\"temperature\": 0, \"max_new_tokens\": 300}\n",
    ")\n",
    "\n",
    "llm = hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab280be3-8b48-467e-80bf-1605ff17d616",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anjiang/anaconda3/envs/chatbot/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n## Answer (1)\\n\\nThe data is available here.\\n\\nThe data is in the form of a table, so you can\\'t use `ggplot2` directly. You can use `tidyverse` to convert the table to a data frame and then plot it.\\n\\n```\\nlibrary(tidyverse)\\n\\n# Read the data\\ndata <- read_csv(\"https://www.census.gov/data/tables/time-series/demo/income-poverty/historical-income-households/cps-historical-income-households.csv\")\\n\\n# Convert the table to a data frame\\ndata <- data %>%\\n  as_tibble() %>%\\n  select(Year, State, Median_Household_Income) %>%\\n  mutate(Year = as.numeric(Year))\\n\\n# Plot the data\\nggplot(data, aes(x = Year, y = Median_Household_Income, color = State)) +\\n  geom_line() +\\n  labs(x = \"Year\", y = \"Median Household Income\")\\n```\\n\\nThis will produce the following plot:\\n\\nComment: Thank you so much! I\\'m still learning R and I\\'m not sure how to use the data frame.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e73a4eb-19b1-4b45-a96b-83290d1921a9",
   "metadata": {},
   "source": [
    "**At a glance, our LLM generates some output that might seem plausible but not accurate or factual. That is because it has not been trained on the census data of recent years.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ee0794-fb8c-43e6-bac1-52bd3e8511f1",
   "metadata": {},
   "source": [
    "- OpenAI GPT-3.5 model (for test purpose only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81428990-041a-466d-8a98-29423290a0bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# chat = ChatOpenAI(temperature=0)\n",
    "# chat.invoke(query)\n",
    "# llm = chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67737c0-66f2-447b-b38b-f7dd63794110",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Q & A chain \n",
    "Now we have both the retrieval system for relevant documents and LLM as QA chatbot ready.\n",
    "\n",
    "We will take our initial query, together with the relevant documents retrieved based on the results of our similarity search, to create a prompt to feed into the LLM. The LLM will take the initial query as the question and relevant documents as the context information to generate a result.\n",
    "\n",
    "Luckily, **LangChain** provides an abstraction of the whole pipeline - **RetrievalQA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1814450-da39-4958-bc9a-8f9ce3c99acf",
   "metadata": {},
   "source": [
    "**Let's first construct a proper prompt for our task.**\n",
    "\n",
    "Prompt engineering is another crucial factor in LLM's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c55f5c61-e016-4c26-9038-b063516835ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. Please follow the following rules:\n",
    "1. If you don't know the answer, don't try to make up an answer. Just say \"I can't find the final answer but you may want to check the following links\".\n",
    "2. If you find the answer, write the answer in a concise way with five sentences maximum.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43bc986-93af-49a6-84cc-eda2456f864f",
   "metadata": {},
   "source": [
    "Call LangChain's RetrievalQA with the prompt above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72e1a9bb-7ecb-475a-a7f7-ca974a8a77a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retrievalQA = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c40cd5-6125-4d9b-8c2c-5a6a31497d4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Use RetrievalQA invoke method to execute the chain\n",
    "Note that Input of [invoke method](https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval_qa.base.RetrievalQA.html#langchain.chains.retrieval_qa.base.RetrievalQA.invoke) needs to be a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5f84ff6-7869-44ca-8310-90adec711b6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anjiang/anaconda3/envs/chatbot/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Call the QA chain with our query.\n",
    "result = retrievalQA.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27ba61d2-ea29-4ca4-b94c-cc64232aa972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The median household income in the United States was $74,755 in 2022, a decline of 0.8 percent from last year, after adjusting for inflation. Real median household income increased in five states and decreased in 17 states from 2021 to 2022. Twenty-eight states, the District of Columbia, and Puerto Rico showed no statistically significant differences.\n",
      "\n",
      "The District of Columbia had the highest median household income of all states ($110,000), followed by Maryland ($94,991), New Jersey ($96,346), and Massachusetts ($93,900). The lowest median household income was in Mississippi ($50,000), followed by Louisiana ($50,100), Arkansas ($50,200), and West Virginia ($50,300).\n",
      "\n",
      "The median household income in the United States was $74,755 in 2022, a decline of 0.8 percent from last year, after adjusting for inflation. Real median household income increased in five states and decreased in 17 states from 2021 to 2022. Twenty-eight states, the District of Columbia, and Puerto Rico showed no statistically significant differences.\n",
      "\n",
      "The District of Columbia had the highest median household income of all states\n"
     ]
    }
   ],
   "source": [
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86191166-20e2-4b1a-aaa4-f4742542adfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 documents retrieved which are relevant to the query.\n",
      "****************************************************************************************************\n",
      "Relevant Document #1:\n",
      "Source file: us_census/acsbr-017.pdf, Page: 1\n",
      "Content: programs-surveys/acs>.\n",
      "HIGHLIGHTS\n",
      "• Median household income in the United States was $74,755 in 2022, a decline of 0.8 percent from last year, after adjusting for inflation.\n",
      "6\n",
      "• Real median household income increased in five states and decreased in 17 states from 2021 to 2022. Twenty-eight states, the District of Columbia, and \n",
      "Puerto Rico showed no statisti-\n",
      "cally significant differences. \n",
      "⁶ All income estimates in this report \n",
      "are inflation-adjusted to 2022 dollars.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Relevant Document #2:\n",
      "Source file: us_census/acsbr-017.pdf, Page: 2\n",
      "Content: U.S. Census Bureau  3\n",
      "Table 1.\n",
      "Median Household Income and Gini Index in the Past 12 Months by State and Puerto Rico:  \n",
      "2021 and 2022\n",
      "(In 2022 inflation-adjusted dollars. Data are limited to the household population and exclude the population living in institutions, college  \n",
      "dormitories, and other group quarters)\n",
      "State2021 ACS median  \n",
      "household income  \n",
      " (dollars)2022 ACS median  \n",
      "household income \n",
      "(dollars)Change in  \n",
      " median income  \n",
      "(percent)2021  \n",
      "ACS Gini  \n",
      "coefficients2022  \n",
      "ACS Gini\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Relevant Document #3:\n",
      "Source file: us_census/acsbr-017.pdf, Page: 3\n",
      "Content: 4 U.S. Census Bureau\n",
      "to the ACS (Table 1). Real median \n",
      "household income in the United \n",
      "States declined 0.8 percent \n",
      "between the 2021 ACS and 2022 \n",
      "ACS.7 Figure 1 shows a historical \n",
      "series of median household income \n",
      "back to 2005.\n",
      "New Jersey and Maryland had the \n",
      "highest median household incomes \n",
      "of all states ($96,346 and $94,991, \n",
      "respectively); there was no statisti -\n",
      "cal difference between the two. \n",
      "⁷ “Real” refers to income after adjusting \n",
      "for inflation.The District of Columbia’s median\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "relevant_docs = result['source_documents']\n",
    "print(f'There are {len(relevant_docs)} documents retrieved which are relevant to the query.')\n",
    "print(\"*\" * 100)\n",
    "for i, doc in enumerate(relevant_docs):\n",
    "    print(f\"Relevant Document #{i+1}:\\nSource file: {doc.metadata['source']}, Page: {doc.metadata['page']}\\nContent: {doc.page_content}\")\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92070ecc-452b-4ef8-a3e7-4b5d13cd548d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- Enhanced Accuracy and Relevance: By leveraging external sources, RAG models can generate content that is more accurate, detailed, and relevant to the given context.\n",
    "- Factuality: It helps in improving the factuality of the generated text, as the information is directly sourced from reliable external databases or knowledge bases.\n",
    "- Versatility: RAG can be applied to a wide range of NLP tasks, including question answering, text summarization, content creation, and more, enhancing their performance by providing access to a broader range of information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
