{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "595082a1-526b-4c96-afe2-9fec2ca2924f",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation (RAG) with open-source Hugging Face LLMs using LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e6fb0d-db38-46df-9b2b-a7b5058c4dac",
   "metadata": {},
   "source": [
    "![RAG pic](pictures/RAG.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcf48ed-bb4f-481e-8051-7c4b2dbceee8",
   "metadata": {},
   "source": [
    "## Introduction: \n",
    "\n",
    "**Retrieval-Augmented Generation (RAG)** is an approach in natural language processing (NLP) that enhances the capabilities of generative models by integrating external knowledge retrieval into the generation process. This technique aims to improve the quality, relevance, and factual accuracy of the generated text by allowing the model to dynamically access and incorporate information from a large corpus of documents or databases during the generation task. The process involves two key components: a retrieval system and a generative model.\n",
    "\n",
    "**Working Mechanism**\n",
    "The working mechanism of RAG typically involves the following steps:\n",
    "\n",
    "- Query Formation: The system formulates a query based on the initial input or prompt. This query is designed to retrieve information that is likely to be relevant to generating the desired output.\n",
    "\n",
    "- Information Retrieval: The formulated query is used to fetch relevant information from an external database or knowledge base. The retrieval system may return one or more documents, passages, or data entries that match the query.\n",
    "\n",
    "- Content Integration: The retrieved information, along with the original input, is provided to the generative model. The model then integrates this information to produce a coherent and contextually enriched output.\n",
    "\n",
    "- Generation: The generative model synthesizes the final text, taking into account both the input and the retrieved external information. This step ensures that the output is not only relevant and informative but also maintains a natural and fluent language style.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5260f0f7-e8a5-4051-9aed-42c7729ac92d",
   "metadata": {},
   "source": [
    "## Library installation\n",
    "- Create a virtual environment and install the necessary python libraries\n",
    "- `pip install transformers sentence-tranformers langchain torch faiss-cpu numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cf1fe1-d539-4099-8967-5ce05c2be2a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Library configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "280bbd1d-5b03-403c-989a-fe44ec3efc27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anjiang/anaconda3/envs/chatbot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330b1dd5-d9b4-466c-ad18-8adb9e785470",
   "metadata": {},
   "source": [
    "## Document preparation\n",
    "**We are going to download 4 publications from United States Census Bureau on the following topics:**\n",
    "- Occupation, Earnings, and Job Characteristics: July 2022\n",
    "- Household Income in States andMetropolitan Areas: 2022\n",
    "- Poverty in States and Metropolitan Areas: 2022\n",
    "- Health Insurance Coverage Status and Type by Geography: 2021 and 2022\n",
    "\n",
    "We prepare this documents for the LLM to use as a knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da88ba1c-1f1f-400f-bc28-b9bd60a1e6d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download documents from U.S. Census Bureau to local directory.\n",
    "os.makedirs(\"us_census\", exist_ok=True)\n",
    "files = [\n",
    "    \"https://www.census.gov/content/dam/Census/library/publications/2022/demo/p70-178.pdf\",\n",
    "    \"https://www.census.gov/content/dam/Census/library/publications/2023/acs/acsbr-017.pdf\",\n",
    "    \"https://www.census.gov/content/dam/Census/library/publications/2023/acs/acsbr-016.pdf\",\n",
    "    \"https://www.census.gov/content/dam/Census/library/publications/2023/acs/acsbr-015.pdf\",\n",
    "]\n",
    "for url in files:\n",
    "    file_path = os.path.join(\"us_census\", url.rpartition(\"/\")[2])\n",
    "    urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fca755-2b10-4cef-a084-fc1596697f7f",
   "metadata": {},
   "source": [
    "**Split documents to smaller chunks** \n",
    "\n",
    "Documents should be: \n",
    "- large enough to contain enough information to answer a question, and \n",
    "- small enough to fit into the LLM prompt: mistralai/Mistral-7B-v0.1 input tokens limited to 4096 tokens\n",
    "- small enough to fit into the embeddings model: WhereIsAI/UAE-Large-V1: input tokens limited to 512 tokens (roughly 2,000 characters. Note: 1 token ~ 4 characters).\n",
    "\n",
    "For this project, we are going to split documents to chunks of roughly 1000 characters with an overlap of 100 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b58c08-9077-4f68-9dd6-0333b5bb10a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load pdf files in the local directory\n",
    "loader = PyPDFDirectoryLoader(\"./us_census/\")\n",
    "\n",
    "docs_before_split = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 100,\n",
    ")\n",
    "docs_after_split = text_splitter.split_documents(docs_before_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11a38354-0612-42ba-bde3-0cfa4514f540",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Health Insurance Coverage Status and Type \\nby Geography: 2021 and 2022\\nAmerican Community Survey Briefs\\nACSBR-015Issued September 2023Douglas Conway and Breauna Branch\\nINTRODUCTION\\nDemographic shifts as well as economic and govern-\\nment policy changes can affect people’s access to health coverage. For example, between 2021 and 2022, the labor market continued to improve, which may have affected private coverage in the United States \\nduring that time.\\n1 Public policy changes included \\nthe renewal of the Public Health Emergency, which \\nallowed Medicaid enrollees to remain covered under the Continuous Enrollment Provision.\\n2 The American \\nRescue Plan (ARP) enhanced Marketplace premium subsidies for those with incomes above 400 percent of the poverty level as well as for unemployed people.\\n3', metadata={'source': 'us_census/acsbr-015.pdf', 'page': 0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_after_split[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79aeb73e-5c39-46b6-b144-395ade93c366",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before split, there were 63 documents loaded, with average characters equal to 3830.\n",
      "After split, there were 296 documents (chunks), with average characters equal to 864 (average chunk length).\n"
     ]
    }
   ],
   "source": [
    "avg_doc_length = lambda docs: sum([len(doc.page_content) for doc in docs])//len(docs)\n",
    "avg_char_before_split = avg_doc_length(docs_before_split)\n",
    "avg_char_after_split = avg_doc_length(docs_after_split)\n",
    "\n",
    "print(f'Before split, there were {len(docs_before_split)} documents loaded, with average characters equal to {avg_char_before_split}.')\n",
    "print(f'After split, there were {len(docs_after_split)} documents (chunks), with average characters equal to {avg_char_after_split} (average chunk length).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b957ff3-df1a-4e75-9192-1b9c8c85927b",
   "metadata": {},
   "source": [
    "## Text Embeddings with Hugging Face models\n",
    "At the time of writing, there are 213 text embeddings models for English on the [Massive Text Embedding Benchmark (MTEB) leaderboard](https://huggingface.co/spaces/mteb/leaderboard). For our project, we are picking a lightweight and powerful open-source model called **UAE-Large-V1**, which is placed in the 6th position on the leaderboard with a much less model size compared to the top 5. An alternative option would be **sentence-transformers (S-BERT)** a classical lightweight embedding model which is also widely used. Note that sentence-tranformers embedding dimension is 384, whereas UAE-Large-V1 has 1024 dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cbff637-d938-445d-b769-a2122ded10f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name WhereIsAI/UAE-Large-V1. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"WhereIsAI/UAE-Large-V1\",  # alternatively use \"sentence-transformers/all-MiniLM-l6-v2\" for a more light-weight experience.\n",
    "    model_kwargs={'device':'cpu'}, \n",
    "    encode_kwargs={'normalize_embeddings': False}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98862ede-96af-4d76-ba54-758eecc11932",
   "metadata": {},
   "source": [
    "Now we can see how a sample embedding would look like for one of those chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b35b55a-3e96-4352-bf5a-5156bb1b5fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample embedding of a document chunk:  [ 0.04481124  0.28892794  0.01964425 ... -0.70755053 -0.06768651\n",
      " -0.41787085]\n",
      "Size of the embedding:  (1024,)\n"
     ]
    }
   ],
   "source": [
    "sample_embedding = np.array(huggingface_embeddings.embed_query(docs_after_split[0].page_content))\n",
    "print(\"Sample embedding of a document chunk: \", sample_embedding)\n",
    "print(\"Size of the embedding: \", sample_embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77031a88-063e-40b7-b543-982e47b037a4",
   "metadata": {},
   "source": [
    "## Retrieval System for vector embeddings\n",
    "Once we have a embedding model, we are ready to vectorize all our documents and store them in a vector store to construct a retrieval system. With specifically designed searching algorithms, a retrieval system can do similarity searching efficiently to retrieve relevant documents.\n",
    "\n",
    "FAISS (Facebook AI Similarity Search) is a library that allows developers to quickly search for embeddings of multimedia documents that are similar to each other. It solves limitations of traditional query search engines that are optimized for hash-based searches, and provides more scalable similarity search functions (nearest-neighbor search implementations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efb25e38-750d-490d-be4a-c15e6d789167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(docs_after_split, huggingface_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "065ce4c9-d269-4c4d-ba44-1856ffaf240f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 documents retrieved which are relevant to the query. Display the first one:\n",
      "\n",
      "for Arizona, Oregon, and Vermont were not statistically different from \n",
      "the U.S. median.\n",
      "From 2021 to 2022, five states—\n",
      "Alabama, Alaska, Delaware, Florida, \n",
      "and Utah—showed a statistically \n",
      "significant increase in real median \n",
      "household income; 17 states \n",
      "showed a decrease. Real median \n",
      "household income in 2022 was not \n",
      "statistically different from that in \n",
      "2021 for 28 states, the District of \n",
      "Columbia, and Puerto Rico  \n",
      "(Table 1).\n",
      "Median Household Income in the Past 12 Months\n",
      "for the United States and Puerto Rico: 2022\n",
      "DCDE\n",
      "TXCAMT\n",
      "AZID\n",
      "NV\n",
      "NMCOILOR\n",
      "UT\n",
      "KSWY\n",
      "IA\n",
      "NESDMN\n",
      "FLND\n",
      "OKWI\n",
      "MOWA\n",
      "AL GA\n",
      "LAARMI\n",
      "INPANY\n",
      "NC\n",
      "MSTNVA\n",
      "KYOH\n",
      "SCME\n",
      "WVVT\n",
      "NH\n",
      "NJMA\n",
      "CT\n",
      "MDRI\n",
      "U.S. median household\n",
      "income is $74,755.$85,000 or more\n",
      "$70,000 to $84,999\n",
      "$60,000 to $69,999\n",
      "Less than $60,000Income by state\n",
      "(2022 inﬂation-adjusted\n",
      "dollars)\n",
      "U.S. median household income\n",
      "does not include Puerto Rico.\n",
      "HIAK\n",
      "Note: A state abbreviation surrounded by the “   ” symbol denotes the value for the state is not statistically diﬀerent from\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"What were the trends in median household income across different states in the United States between 2021 and 2022.\"\"\"  # Sample question, change to other questions you are interested in.\n",
    "relevant_documents = vectorstore.similarity_search(query)\n",
    "print(f'There are {len(relevant_documents)} documents retrieved which are relevant to the query. Display the first one:\\n')\n",
    "print(relevant_documents[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105646d7-b417-41d2-b981-48cae9e20496",
   "metadata": {},
   "source": [
    "### Create a retriever interface using vectorstore, we'll use it later to construct Q & A chain using LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15c6b860-1146-4256-8aad-5dd5cc245f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use similarity searching algorithm and return 3 most relevant documents.\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2623c760-f5b5-4a07-b303-d33f195b0746",
   "metadata": {},
   "source": [
    "**Now we have our vector store and retrieval system ready. We then need a large language model (LLM) to process information and answer the question.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a8300b-3a58-4026-bf1c-b18ebc7c9c15",
   "metadata": {},
   "source": [
    "## Open-source LLMs from Hugging Face\n",
    "**There two ways to utilize Hugging Face LLMs: online and local.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b62e27-1ce6-41c4-b25e-c154c7cf3cc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hugging Face Hub\n",
    "The Hugging Face Hub is an platform with over 350k models, 75k datasets, and 150k demo apps (Spaces), all open source and publicly available, in an online platform where people can easily collaborate and build ML together. \n",
    "\n",
    "- To use, we should have the huggingface_hub python package installed.\n",
    "- Set an environment variable called HUGGINGFACEHUB_API_TOKEN with your Hugging Face access token in it.\n",
    "- Currently, HuggingFace LangChain integration doesn't support the question-answering task, so we can't select HuggingFace QA models for this project. Instead, we select LLMs from the text-generation task category.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cefbd53a-51c1-4c1a-a05c-b9b0aaa1593a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "# hf = HuggingFaceHub(\n",
    "#     repo_id=\"EleutherAI/gpt-neo-2.7B\",\n",
    "#     model_kwargs={\"temperature\":0.1, \"max_length\":500})\n",
    "\n",
    "#query = \"\"\"What were the trends in median household income across different states in the United States between 2021 and 2022.\"\"\"  # Sample question, change to other questions you are interested in.\n",
    "# hf.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae62f871-4ee2-4296-9a81-53f7eb95f822",
   "metadata": {},
   "source": [
    "### Hugging Face Local Pipelines\n",
    "\n",
    "Hugging Face models can be run locally through the HuggingFacePipeline class.\n",
    "\n",
    "- We need to install transformers python package.\n",
    "- The Mistral-7B-v0.1 Large Language Model (LLM) is a pretrained generative text model with 7 billion parameters. Mistral-7B-v0.1 outperforms Llama-2-13B on all benchmarks tested. Read the [paper](https://arxiv.org/abs/2310.06825).\n",
    "- Mistral-7B-v0.1's model size is 3.5GB, while Llama-2–13B has 13 billion parameters and 25GB model size.\n",
    "- In order to use Llama2, you need to request access from Meta. Mistral-7B-v0.1 is publically available already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35c9a472-a34d-418d-a129-971b987fb023",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:18<00:00,  9.31s/it]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "hf = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"mistralai/Mistral-7B-v0.1\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\"max_new_tokens\": 300}\n",
    ")\n",
    "\n",
    "llm = hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab280be3-8b48-467e-80bf-1605ff17d616",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n## Answer (1)\\n\\nThe data is available here.\\n\\nThe data is in the form of a table, so you can\\'t use `ggplot2` directly. You can use `tidyverse` to convert the table to a data frame and then plot it.\\n\\n```\\nlibrary(tidyverse)\\n\\n# Read the data\\ndata <- read_csv(\"https://www.census.gov/data/tables/time-series/demo/income-poverty/historical-income-households/cps-historical-income-households.csv\")\\n\\n# Convert the table to a data frame\\ndata <- data %>%\\n  as_tibble() %>%\\n  select(Year, State, Median_Household_Income) %>%\\n  mutate(Year = as.numeric(Year))\\n\\n# Plot the data\\nggplot(data, aes(x = Year, y = Median_Household_Income, color = State)) +\\n  geom_line() +\\n  labs(x = \"Year\", y = \"Median Household Income\")\\n```\\n\\nThis will produce the following plot:\\n\\nComment: Thank you so much! I\\'m still learning R and I\\'m not sure how to use the data frame.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e73a4eb-19b1-4b45-a96b-83290d1921a9",
   "metadata": {},
   "source": [
    "**At a glance, our LLM generates some output that might seem plausible but not accurate or factual. That is because it has not been trained on the census data of recent years.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ee0794-fb8c-43e6-bac1-52bd3e8511f1",
   "metadata": {},
   "source": [
    "- OpenAI GPT-3.5 model (for test purpose only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81428990-041a-466d-8a98-29423290a0bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# chat = ChatOpenAI(temperature=0)\n",
    "# chat.invoke(query)\n",
    "# llm = chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67737c0-66f2-447b-b38b-f7dd63794110",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Q & A chain \n",
    "Now we have both the retrieval system for relevant documents and LLM as QA chatbot ready.\n",
    "\n",
    "We will take our initial query, together with the relevant documents retreived based on the results of our similarity search, to create a prompt to feed into the LLM. The LLM will take the initial query as the question and relevant documents as the context information to generate a result.\n",
    "\n",
    "Luckily, **LangChain** provides an abstraction of the whole pipeline - **RetrievalQA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1814450-da39-4958-bc9a-8f9ce3c99acf",
   "metadata": {},
   "source": [
    "**Let's first construct a proper prompt for our task.**\n",
    "\n",
    "Prompt engineering is another crucial factor in LLM's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c55f5c61-e016-4c26-9038-b063516835ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. Please follow the following rules:\n",
    "1. If you don't know the answer, don't try to make up an answer. Just say \"I can't find the final answer but you may want to check the following links\".\n",
    "2. If you find the answer, write the answer in a concise way with five sentences maximum.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43bc986-93af-49a6-84cc-eda2456f864f",
   "metadata": {},
   "source": [
    "Call LangChain's RetrievalQA with the prompt above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72e1a9bb-7ecb-475a-a7f7-ca974a8a77a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retrievalQA = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c40cd5-6125-4d9b-8c2c-5a6a31497d4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Use RetrievalQA invoke method to execute the chain\n",
    "Note that Input of [invoke method](https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval_qa.base.RetrievalQA.html#langchain.chains.retrieval_qa.base.RetrievalQA.invoke) needs to be a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5f84ff6-7869-44ca-8310-90adec711b6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Call the QA chain with our query.\n",
    "result = retrievalQA.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27ba61d2-ea29-4ca4-b94c-cc64232aa972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The U.S. median household income in 2022 was $74,755, according to the American Community Survey (ACS). The ACS is a nationwide survey that provides data on the social, economic, housing, and demographic characteristics of the U.S. population. The ACS is conducted by the U.S. Census Bureau and is based on a sample of households.\n",
      "\n",
      "The ACS data show that median household income in the United States increased from 2021 to 2022. The increase was driven by increases in median household income in 20 states, including California, Florida, and Texas. The median household income in the remaining 30 states and the District of Columbia was not statistically different from the U.S. median.\n",
      "\n",
      "The ACS data also show that median household income in the United States increased from 2021 to 2022. The increase was driven by increases in median household income in 20 states, including California, Florida, and Texas. The median household income in the remaining 30 states and the District of Columbia was not statistically different from the U.S. median.\n",
      "\n",
      "The ACS data also show that median household income in the United States increased from 2021 to 2022. The increase was driven by increases in median household income in 20 states, including California\n"
     ]
    }
   ],
   "source": [
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86191166-20e2-4b1a-aaa4-f4742542adfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 documents retrieved which are relevant to the query.\n",
      "****************************************************************************************************\n",
      "Relevant Document #1:\n",
      "Source file: us_census/acsbr-017.pdf, Page: 3\n",
      "Content: for Arizona, Oregon, and Vermont were not statistically different from \n",
      "the U.S. median.\n",
      "From 2021 to 2022, five states—\n",
      "Alabama, Alaska, Delaware, Florida, \n",
      "and Utah—showed a statistically \n",
      "significant increase in real median \n",
      "household income; 17 states \n",
      "showed a decrease. Real median \n",
      "household income in 2022 was not \n",
      "statistically different from that in \n",
      "2021 for 28 states, the District of \n",
      "Columbia, and Puerto Rico  \n",
      "(Table 1).\n",
      "Median Household Income in the Past 12 Months\n",
      "for the United States and Puerto Rico: 2022\n",
      "DCDE\n",
      "TXCAMT\n",
      "AZID\n",
      "NV\n",
      "NMCOILOR\n",
      "UT\n",
      "KSWY\n",
      "IA\n",
      "NESDMN\n",
      "FLND\n",
      "OKWI\n",
      "MOWA\n",
      "AL GA\n",
      "LAARMI\n",
      "INPANY\n",
      "NC\n",
      "MSTNVA\n",
      "KYOH\n",
      "SCME\n",
      "WVVT\n",
      "NH\n",
      "NJMA\n",
      "CT\n",
      "MDRI\n",
      "U.S. median household\n",
      "income is $74,755.$85,000 or more\n",
      "$70,000 to $84,999\n",
      "$60,000 to $69,999\n",
      "Less than $60,000Income by state\n",
      "(2022 inﬂation-adjusted\n",
      "dollars)\n",
      "U.S. median household income\n",
      "does not include Puerto Rico.\n",
      "HIAK\n",
      "Note: A state abbreviation surrounded by the “   ” symbol denotes the value for the state is not statistically diﬀerent from\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Relevant Document #2:\n",
      "Source file: us_census/acsbr-017.pdf, Page: 1\n",
      "Content: 6\n",
      "• Real median household income increased in five states and decreased in 17 states from 2021 to 2022. Twenty-eight states, the District of Columbia, and \n",
      "Puerto Rico showed no statisti-\n",
      "cally significant differences. \n",
      "⁶ All income estimates in this report \n",
      "are inflation-adjusted to 2022 dollars. \n",
      "Inflation adjustments are computed using \n",
      "the Consumer Price Index retroactive series \n",
      "using current methods (R-CPI-U-RS).• New Jersey and Maryland had \n",
      "the highest median household incomes of all states—$96,346 and $94,991, respectively—and were not statistically different \n",
      "from each other. The District of \n",
      "Columbia’s median household income ($101,027) was the high-est in the nation. Mississippi had the lowest median household income ($52,719) of any state.\n",
      "• Income inequality in the United States measured by the Gini index increased between 2021 and 2022.\n",
      "MEDIAN HOUSEHOLD INCOME\n",
      "2021 and 2022 National and State Comparisons\n",
      "The U.S. median household income \n",
      "in 2022 was $74,755, according\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Relevant Document #3:\n",
      "Source file: us_census/acsbr-017.pdf, Page: 6\n",
      "Content: Table 3. There was no statisti -\n",
      "cally significant change in median \n",
      "household income between 2021 \n",
      "and 2022 for the remaining age \n",
      "groups. Households with a house -\n",
      "holder aged 45 to 64 had the high -\n",
      "est median household income in \n",
      "2022 ($90,748), followed by those with householders aged 25 to 44 \n",
      "($83,783), and then those with \n",
      "householders 65 years and older \n",
      "($53,963). Households maintained \n",
      "by householders under the age of \n",
      "25 had the lowest median house -\n",
      "hold income ($42,079).\n",
      "INCOME INEQUALITY\n",
      "The Gini index for the United \n",
      "States in 2022 (0.486) was higher \n",
      "than in 2021 (0.485). Between \n",
      "2021 and 2022, the ACS Gini index \n",
      "increased in eight states: California, \n",
      "Indiana, Kentucky, Massachusetts, \n",
      "Minnesota, New York, Oklahoma, \n",
      "and Pennsylvania. The District of \n",
      "Columbia, Louisiana, Tennessee, \n",
      "and Utah had lower Gini indexes \n",
      "than in 2021. Changes from 2021 \n",
      "were not statistically significant \n",
      "for the other 39 states and Puerto \n",
      "Rico. Among the 50 states, New\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "relevant_docs = result['source_documents']\n",
    "print(f'There are {len(relevant_docs)} documents retrieved which are relevant to the query.')\n",
    "print(\"*\" * 100)\n",
    "for i, doc in enumerate(relevant_docs):\n",
    "    print(f\"Relevant Document #{i+1}:\\nSource file: {doc.metadata['source']}, Page: {doc.metadata['page']}\\nContent: {doc.page_content}\")\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92070ecc-452b-4ef8-a3e7-4b5d13cd548d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- Enhanced Accuracy and Relevance: By leveraging external sources, RAG models can generate content that is more accurate, detailed, and relevant to the given context.\n",
    "- Factuality: It helps in improving the factuality of the generated text, as the information is directly sourced from reliable external databases or knowledge bases.\n",
    "- Versatility: RAG can be applied to a wide range of NLP tasks, including question answering, text summarization, content creation, and more, enhancing their performance by providing access to a broader range of information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
